{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekGiri1617/Stock-Forcasting/blob/main/MYStockForcasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests joblib numpy pandas yfinance matplotlib statsmodels arch scipy tensorflow scikit-learn xgboost transformers shap ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0_l0JKbogCE",
        "outputId": "af276521-9ed6-4295-f36d-b2598d5f4542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Collecting arch\n",
            "  Downloading arch-7.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.61.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.44.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading arch-7.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (985 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m985.3/985.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=cab6dfff37a42c2b239d28403b19fdad9448aaee3f2fc252d2b995b843dc84ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta, arch\n",
            "Successfully installed arch-7.2.0 ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HiTFnI8xau0x",
        "outputId": "11df6413-8d6b-4bcd-aebc-2d40f254385a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU found, enabling memory growth.\n",
            "Welcome to the Stock Analysis CLI!\n",
            "Type 'help' for a list of commands or 'exit' to quit.\n",
            "Command not recognized. Type 'help' for a list of commands.\n",
            "Command not recognized. Type 'help' for a list of commands.\n",
            "\n",
            "Available Commands:\n",
            "\n",
            "Basic Analysis:\n",
            "  raw TICKER                  -> Display first 5 and last 5 rows of raw data for TICKER\n",
            "  preprocessed TICKER         -> Display cleaned data (first 5 & last 5 rows) for TICKER\n",
            "  features TICKER             -> Display technical indicators (first 5 & last 5 rows) for TICKER\n",
            "  evaluation TICKER           -> Evaluate model and show error metrics with forecast\n",
            "  advanced TICKER             -> Forecast using an advanced (Transformer-based) model\n",
            "  sentiment HEADLINE          -> Analyze sentiment of a news headline\n",
            "\n",
            "Data Splitting:\n",
            "  split TICKER                -> Split data into training and testing sets\n",
            "\n",
            "Forecasting & Comparison:\n",
            "  oneday TICKER               -> 1-day forecast using combined (ensemble) models\n",
            "  arima TICKER                -> 1-day forecast using ARIMA\n",
            "  lstm TICKER                 -> 1-day forecast using LSTM\n",
            "  gru TICKER                  -> 1-day forecast using GRU\n",
            "  rf TICKER                   -> 1-day forecast using RandomForest\n",
            "  gb TICKER                   -> 1-day forecast using XGBoost\n",
            "  combined TICKER             -> 1-day forecast using ensemble models (average)\n",
            "  predict TICKER DAYS [MODEL] -> Forecast for custom horizon (default: lstm)\n",
            "  interactive TICKER DAYS [MODEL] -> Interactive forecast visualization (Plotly)\n",
            "  candlestick TICKER [PERIOD] [INTERVAL] -> Interactive candlestick chart\n",
            "\n",
            "Stock Info & Analysis:\n",
            "  info TICKER                 -> Display stock information\n",
            "  analyze TICKER              -> Comprehensive analysis (info, technicals, 5-day forecast)\n",
            "  yahoo TICKER                -> Yahoo Finance-like dashboard\n",
            "\n",
            "Probability:\n",
            "  probability TICKER          -> Buy/Sell probability (30-day horizon, default: ensemble)\n",
            "\n",
            "Visualization:\n",
            "  chart TICKER                -> Display raw ticker chart\n",
            "  context TICKER [MODEL]      -> Last 6 days historical + next 6 days forecast (default: ensemble)\n",
            "  zoom TICKER [MODEL]         -> 15-day zoom forecast chart (default: combined)\n",
            "\n",
            "Backtesting:\n",
            "  walkforward TICKER          -> Perform walk-forward validation\n",
            "\n",
            "Portfolio Management:\n",
            "  portfolio add TICKER SHARES -> Add shares of TICKER to portfolio\n",
            "  portfolio show              -> Display current portfolio\n",
            "  portfolio clear             -> Clear portfolio\n",
            "\n",
            "FINAL Command:\n",
            "  final TICKER DAYS [MODEL]   -> Shows everything about projections in one shot (with unified explanation)\n",
            "\n",
            "Misc:\n",
            "  rawticker TICKER            -> Display first 5 and last 5 rows of raw data for TICKER\n",
            "  help                        -> Show this help message\n",
            "  exit                        -> Quit the CLI\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Error in RF forecast: Found input variables with inconsistent numbers of samples: [537, 536]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Individual Model Forecasts:\n",
            "  ARIMA: ['$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05', '$3493.05']\n",
            "  LSTM: ['$3675.01', '$3646.77', '$3628.17', '$3615.88', '$3607.73', '$3602.28', '$3598.61', '$3596.13', '$3594.45', '$3593.32', '$3592.57', '$3592.10', '$3591.84', '$3591.74', '$3591.75', '$3591.86', '$3592.04', '$3592.27', '$3592.54', '$3592.85', '$3593.18', '$3593.52', '$3593.88', '$3594.24', '$3594.60', '$3594.96', '$3595.33', '$3595.69', '$3596.04', '$3596.39']\n",
            "  GRU: ['$3562.92', '$3566.75', '$3579.73', '$3594.06', '$3608.71', '$3623.58', '$3638.61', '$3653.78', '$3669.05', '$3684.39', '$3699.81', '$3715.29', '$3730.83', '$3746.41', '$3762.05', '$3777.72', '$3793.43', '$3809.18', '$3824.95', '$3840.74', '$3856.56', '$3872.38', '$3888.21', '$3904.03', '$3919.86', '$3935.67', '$3951.46', '$3967.23', '$3982.98', '$3998.68']\n",
            "  XGB: ['$3557.07', '$3626.49', '$3625.28', '$3626.43', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82', '$3626.82']\n",
            "\n",
            "Ensemble Forecast: ['$3572.01', '$3583.27', '$3581.56', '$3582.36', '$3584.08', '$3586.43', '$3589.27', '$3592.45', '$3595.84', '$3599.39', '$3603.06', '$3606.82', '$3610.63', '$3614.51', '$3618.42', '$3622.36', '$3626.34', '$3630.33', '$3634.34', '$3638.37', '$3642.40', '$3646.44', '$3650.49', '$3654.53', '$3658.58', '$3662.63', '$3666.66', '$3670.70', '$3674.72', '$3678.74']\n",
            "\n",
            "Buy/Sell Probability for TCS.NS (30-day horizon):\n",
            "  Current Price: $3493.05\n",
            "  Probability of Price Increase: 100.0%\n",
            "  Probability of Price Decrease: 0.0%\n",
            "  Expected Return: 3.71%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d5e3e0b1fe6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     \u001b[0mcommand_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-d5e3e0b1fe6f>\u001b[0m in \u001b[0;36mcommand_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Type 'help' for a list of commands or 'exit' to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_thread\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcurrent_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mstop_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cancel any running task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import threading, asyncio, requests, os, joblib, logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from math import sqrt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from arch import arch_model\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Neural network forecasting (TensorFlow)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Ensemble forecasting\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Transformer-based forecasting (Advanced)\n",
        "from transformers import pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
        "\n",
        "# SHAP for model interpretability\n",
        "import shap\n",
        "\n",
        "# Technical analysis\n",
        "import ta\n",
        "from ta.trend import SMAIndicator, EMAIndicator, MACD\n",
        "from ta.momentum import RSIIndicator, StochasticOscillator\n",
        "from ta.volatility import BollingerBands\n",
        "from ta.volume import OnBalanceVolumeIndicator\n",
        "\n",
        "# Plotly for interactive charts\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Enable GPU if available\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    print(\"GPU found, enabling memory growth.\")\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "else:\n",
        "    print(\"No GPU found. Running on CPU.\")\n",
        "\n",
        "# Set up logging and directories\n",
        "log_dir = 'logs'\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "model_dir = 'models'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "plot_dir = 'plots'\n",
        "os.makedirs(plot_dir, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.FileHandler(f\"{log_dir}/stock_analysis_{datetime.now().strftime('%Y%m%d')}.log\"),\n",
        "              logging.StreamHandler()]\n",
        ")\n",
        "\n",
        "# Global variables and caching\n",
        "portfolio = {}\n",
        "cached_data = {}\n",
        "stop_event = threading.Event()\n",
        "\n",
        "###############################################################################\n",
        "# Data Download & Preprocessing\n",
        "###############################################################################\n",
        "def download_and_preprocess(ticker, years=3, force_download=False):\n",
        "    cache_key = f\"{ticker.upper()}_{years}\"\n",
        "    if not force_download and cache_key in cached_data:\n",
        "        logging.info(f\"Using cached data for {ticker.upper()}\")\n",
        "        return cached_data[cache_key].copy()\n",
        "    end_date = pd.Timestamp.today()\n",
        "    start_date = end_date - pd.DateOffset(years=years)\n",
        "    logging.info(f\"Downloading data for {ticker.upper()} from {start_date.date()} to {end_date.date()}\")\n",
        "    df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "    if df.empty:\n",
        "        logging.error(f\"No data found for ticker '{ticker.upper()}'.\")\n",
        "        return None\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)\n",
        "    df.ffill(inplace=True)\n",
        "    df.interpolate(method='linear', inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    if not isinstance(df.index, pd.DatetimeIndex):\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "    cached_data[cache_key] = df.copy()\n",
        "    return df\n",
        "\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        if stop_event.is_set():\n",
        "            return None, None\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def raw_ticker_values(ticker):\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is not None:\n",
        "        print(\"First 5 rows:\")\n",
        "        print(df.head().to_string())\n",
        "        print(\"\\nLast 5 rows:\")\n",
        "        print(df.tail().to_string())\n",
        "\n",
        "###############################################################################\n",
        "# Sentiment Analysis\n",
        "###############################################################################\n",
        "def analyze_sentiment(text):\n",
        "    result = sentiment_analyzer(text)[0]\n",
        "    return result\n",
        "\n",
        "###############################################################################\n",
        "# Feature Engineering\n",
        "###############################################################################\n",
        "def add_volatility_features(df, window=21):\n",
        "    df = df.copy()\n",
        "    df['Rolling_Volatility'] = df['Close'].pct_change().rolling(window=window).std()\n",
        "    return df\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    df_tech = df.copy()\n",
        "    df_tech['SMA20'] = SMAIndicator(close=df_tech['Close'], window=20).sma_indicator()\n",
        "    df_tech['SMA50'] = SMAIndicator(close=df_tech['Close'], window=50).sma_indicator()\n",
        "    df_tech['SMA200'] = SMAIndicator(close=df_tech['Close'], window=200).sma_indicator()\n",
        "    df_tech['EMA12'] = EMAIndicator(close=df_tech['Close'], window=12).ema_indicator()\n",
        "    df_tech['EMA26'] = EMAIndicator(close=df_tech['Close'], window=26).ema_indicator()\n",
        "    macd = MACD(close=df_tech['Close'])\n",
        "    df_tech['MACD'] = macd.macd()\n",
        "    df_tech['MACD_Signal'] = macd.macd_signal()\n",
        "    df_tech['MACD_Hist'] = macd.macd_diff()\n",
        "    rsi = RSIIndicator(close=df_tech['Close'])\n",
        "    df_tech['RSI'] = rsi.rsi()\n",
        "    stoch = StochasticOscillator(high=df_tech['High'], low=df_tech['Low'], close=df_tech['Close'])\n",
        "    df_tech['Stoch_K'] = stoch.stoch()\n",
        "    df_tech['Stoch_D'] = stoch.stoch_signal()\n",
        "    bb = BollingerBands(close=df_tech['Close'])\n",
        "    df_tech['BB_High'] = bb.bollinger_hband()\n",
        "    df_tech['BB_Low'] = bb.bollinger_lband()\n",
        "    df_tech['BB_Mid'] = bb.bollinger_mavg()\n",
        "    df_tech['BB_Width'] = (df_tech['BB_High'] - df_tech['BB_Low']) / df_tech['BB_Mid']\n",
        "    obv = OnBalanceVolumeIndicator(close=df_tech['Close'], volume=df_tech['Volume'])\n",
        "    df_tech['OBV'] = obv.on_balance_volume()\n",
        "    df_tech['Returns'] = df_tech['Close'].pct_change() * 100\n",
        "    df_tech['Log_Returns'] = np.log(df_tech['Close'] / df_tech['Close'].shift(1)) * 100\n",
        "    df_tech['Volatility'] = df_tech['Returns'].rolling(window=20).std()\n",
        "    df_tech['Daily_Range'] = (df_tech['High'] - df_tech['Low']) / df_tech['Close'] * 100\n",
        "    df_tech['Gap'] = (df_tech['Open'] - df_tech['Close'].shift(1)) / df_tech['Close'].shift(1) * 100\n",
        "    df_tech['Volume_MA'] = df_tech['Volume'].rolling(window=20).mean()\n",
        "    df_tech = add_volatility_features(df_tech)\n",
        "    df_tech.dropna(inplace=True)\n",
        "    return df_tech\n",
        "\n",
        "def split_data_with_features(ticker, train_ratio=0.7, add_features=True):\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is None:\n",
        "        return None, None\n",
        "    if add_features:\n",
        "        df = add_technical_indicators(df)\n",
        "    n = len(df)\n",
        "    split_idx = int(n * train_ratio)\n",
        "    train = df.iloc[:split_idx]\n",
        "    test = df.iloc[split_idx:]\n",
        "    print(f\"Data split for {ticker.upper()}:\")\n",
        "    print(\"Training set (first 5 rows):\")\n",
        "    print(train.head().to_string())\n",
        "    print(\"\\nTraining set (last 5 rows):\")\n",
        "    print(train.tail().to_string())\n",
        "    print(\"\\nTesting set (first 5 rows):\")\n",
        "    print(test.head().to_string())\n",
        "    print(\"\\nTesting set (last 5 rows):\")\n",
        "    print(test.tail().to_string())\n",
        "    return train, test\n",
        "\n",
        "###############################################################################\n",
        "# Forecast Functions\n",
        "###############################################################################\n",
        "def forecast_arima(ticker, days=1, df_input=None, order=(0,1,0)):\n",
        "    if stop_event.is_set():\n",
        "        return None\n",
        "    df = download_and_preprocess(ticker) if df_input is None else df_input.copy()\n",
        "    if df is None:\n",
        "        return None\n",
        "    close_series = df['Close']\n",
        "    try:\n",
        "        log_series = np.log(close_series)\n",
        "        model = ARIMA(log_series, order=order)\n",
        "        model_fit = model.fit()\n",
        "        log_forecast = model_fit.forecast(steps=days)\n",
        "        forecasted_prices = np.exp(log_forecast)\n",
        "        forecasted_prices = [p if p > 0 and not np.isnan(p) else close_series.iloc[-1] for p in forecasted_prices]\n",
        "        return forecasted_prices\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during ARIMA forecasting: {e}\")\n",
        "        return None\n",
        "\n",
        "def forecast_lstm(ticker, days=1, df_input=None):\n",
        "    if stop_event.is_set():\n",
        "        return None\n",
        "    df = download_and_preprocess(ticker) if df_input is None else df_input.copy()\n",
        "    if df is None:\n",
        "        return None\n",
        "    data = df['Close'].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    seq_length = 60\n",
        "    if len(scaled_data) < seq_length:\n",
        "        print(\"Not enough data for LSTM forecasting.\")\n",
        "        return None\n",
        "    X, y = create_sequences(scaled_data, seq_length)\n",
        "    if X is None:\n",
        "        return None\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    with tf.device('/GPU:0') if physical_devices else tf.device('/CPU:0'):\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(50, return_sequences=False))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(1, kernel_regularizer=l2(0.001)))\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "        model.fit(X, y, epochs=50, batch_size=32, verbose=0, callbacks=[es])\n",
        "        last_seq = scaled_data[-seq_length:]\n",
        "        preds = []\n",
        "        current_seq = last_seq.copy()\n",
        "        for _ in range(days):\n",
        "            current_seq_reshaped = current_seq.reshape(1, seq_length, 1)\n",
        "            next_pred = model.predict(current_seq_reshaped, verbose=0)[0, 0]\n",
        "            preds.append(next_pred)\n",
        "            current_seq = np.append(current_seq[1:], [[next_pred]], axis=0)\n",
        "        preds = np.array(preds).reshape(-1, 1)\n",
        "        forecast_prices = scaler.inverse_transform(preds).flatten()\n",
        "    return forecast_prices\n",
        "\n",
        "def forecast_gru(ticker, days=1, df_input=None):\n",
        "    if stop_event.is_set():\n",
        "        return None\n",
        "    df = download_and_preprocess(ticker) if df_input is None else df_input.copy()\n",
        "    if df is None:\n",
        "        return None\n",
        "    data = df['Close'].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    seq_length = 60\n",
        "    if len(scaled_data) < seq_length:\n",
        "        print(\"Not enough data for GRU forecasting.\")\n",
        "        return None\n",
        "    X, y = create_sequences(scaled_data, seq_length)\n",
        "    if X is None:\n",
        "        return None\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    with tf.device('/GPU:0') if physical_devices else tf.device('/CPU:0'):\n",
        "        model = Sequential()\n",
        "        model.add(GRU(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(GRU(50, return_sequences=False))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(1, kernel_regularizer=l2(0.001)))\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "        model.fit(X, y, epochs=50, batch_size=32, verbose=0, callbacks=[es])\n",
        "        last_seq = scaled_data[-seq_length:]\n",
        "        preds = []\n",
        "        current_seq = last_seq.copy()\n",
        "        for _ in range(days):\n",
        "            current_seq_reshaped = current_seq.reshape(1, seq_length, 1)\n",
        "            next_pred = model.predict(current_seq_reshaped, verbose=0)[0, 0]\n",
        "            preds.append(next_pred)\n",
        "            current_seq = np.append(current_seq[1:], [[next_pred]], axis=0)\n",
        "        preds = np.array(preds).reshape(-1, 1)\n",
        "        forecast_prices = scaler.inverse_transform(preds).flatten()\n",
        "    return forecast_prices\n",
        "\n",
        "def forecast_rf(ticker, days=1, df_input=None):\n",
        "    if stop_event.is_set():\n",
        "        return None\n",
        "    df = download_and_preprocess(ticker) if df_input is None else df_input.copy()\n",
        "    if df is None:\n",
        "        return None\n",
        "    df = add_technical_indicators(df)\n",
        "    for lag in range(1, 6):\n",
        "        df[f'Close_lag_{lag}'] = df['Close'].shift(lag)\n",
        "    df.dropna(inplace=True)\n",
        "    feature_cols = [col for col in df.columns if col.startswith('Close_lag_')] + ['SMA20', 'SMA50', 'RSI', 'MACD', 'Volume_MA']\n",
        "    X = df[feature_cols].values\n",
        "    y = df['Close'].shift(-1).dropna().values\n",
        "    df = df.iloc[:-1]\n",
        "    model = RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42)\n",
        "    model.fit(X, y)\n",
        "    last_values = df[feature_cols].iloc[-1:].values\n",
        "    forecasts = []\n",
        "    for _ in range(days):\n",
        "        if stop_event.is_set():\n",
        "            return None\n",
        "        pred = model.predict(last_values)[0]\n",
        "        forecasts.append(pred)\n",
        "        new_lags = np.roll(last_values[0, :5], 1)\n",
        "        new_lags[0] = pred\n",
        "        last_values = np.hstack((new_lags, last_values[0, 5:])).reshape(1, -1)\n",
        "    return forecasts\n",
        "\n",
        "def forecast_gb(ticker, days=1, df_input=None, load_model=True):\n",
        "    if stop_event.is_set():\n",
        "        return None\n",
        "    df = download_and_preprocess(ticker) if df_input is None else df_input.copy()\n",
        "    if df is None:\n",
        "        return None\n",
        "    df = add_technical_indicators(df)\n",
        "    for lag in range(1, 6):\n",
        "        df[f'Close_lag_{lag}'] = df['Close'].shift(lag)\n",
        "    df.dropna(inplace=True)\n",
        "    feature_cols = [col for col in df.columns if col.startswith('Close_lag_')] + ['SMA20', 'SMA50', 'RSI', 'MACD', 'Volume_MA']\n",
        "    model_path = f\"{model_dir}/{ticker.upper()}_xgb_model.pkl\"\n",
        "    params = {'n_estimators': 200, 'learning_rate': 0.1, 'random_state': 42, 'verbosity': 0}\n",
        "    if len(physical_devices) > 0:\n",
        "        params['tree_method'] = 'gpu_hist'\n",
        "    if load_model and os.path.exists(model_path):\n",
        "        model = joblib.load(model_path)\n",
        "    else:\n",
        "        df['Target'] = df['Close'].shift(-1)\n",
        "        df.dropna(inplace=True)\n",
        "        X = df[feature_cols].values\n",
        "        y = df['Target'].values\n",
        "        model = xgb.XGBRegressor(**params)\n",
        "        model.fit(X, y)\n",
        "        joblib.dump(model, model_path)\n",
        "    last_values = df[feature_cols].iloc[-1:].values\n",
        "    forecasts = []\n",
        "    for _ in range(days):\n",
        "        if stop_event.is_set():\n",
        "            return None\n",
        "        pred = model.predict(last_values)[0]\n",
        "        forecasts.append(pred)\n",
        "        new_lags = np.roll(last_values[0, :5], 1)\n",
        "        new_lags[0] = pred\n",
        "        last_values = np.hstack((new_lags, last_values[0, 5:])).reshape(1, -1)\n",
        "    return forecasts\n",
        "\n",
        "def ensemble_forecast(ticker, days=1, df_input=None):\n",
        "    if stop_event.is_set():\n",
        "        return None\n",
        "    forecasts = {}\n",
        "    model_funcs = {\n",
        "        'ARIMA': forecast_arima,\n",
        "        'LSTM': forecast_lstm,\n",
        "        'GRU': forecast_gru,\n",
        "        'RF': forecast_rf,\n",
        "        'XGB': forecast_gb\n",
        "    }\n",
        "    for name, func in model_funcs.items():\n",
        "        try:\n",
        "            res = func(ticker, days=days, df_input=df_input)\n",
        "            if res is not None:\n",
        "                forecasts[name] = res\n",
        "                logging.info(f\"{name} forecast generated.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in {name} forecast: {e}\")\n",
        "    if not forecasts:\n",
        "        logging.error(\"No forecasts generated by any model.\")\n",
        "        return None\n",
        "    ensemble = []\n",
        "    for i in range(days):\n",
        "        day_vals = [forecasts[m][i] for m in forecasts if i < len(forecasts[m])]\n",
        "        ensemble.append(np.mean(day_vals))\n",
        "    print(\"\\nIndividual Model Forecasts:\")\n",
        "    for m in forecasts:\n",
        "        print(f\"  {m}: {[f'${p:.2f}' for p in forecasts[m]]}\")\n",
        "    print(f\"\\nEnsemble Forecast: {[f'${p:.2f}' for p in ensemble]}\")\n",
        "    return ensemble\n",
        "\n",
        "###############################################################################\n",
        "# Advanced Transformer-based Model\n",
        "###############################################################################\n",
        "def build_transformer_model(seq_length, d_model=64, num_heads=4, ff_dim=128):\n",
        "    inputs = tf.keras.Input(shape=(seq_length, 1))\n",
        "    x = tf.keras.layers.Dense(d_model)(inputs)\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
        "    x = tf.keras.layers.Add()([x, attn_output])\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    ffn_output = tf.keras.layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ffn_output = tf.keras.layers.Dense(d_model)(ffn_output)\n",
        "    x = tf.keras.layers.Add()([x, ffn_output])\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = tf.keras.layers.Dense(1, kernel_regularizer=l2(0.001))(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "def forecast_tft(ticker, days=1):\n",
        "    if stop_event.is_set():\n",
        "        return None\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is None:\n",
        "        return None\n",
        "    data = df['Close'].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    seq_length = 60\n",
        "    if len(scaled_data) < seq_length:\n",
        "        print(\"Not enough data for Transformer forecasting.\")\n",
        "        return None\n",
        "    X, y = create_sequences(scaled_data, seq_length)\n",
        "    if X is None:\n",
        "        return None\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    with tf.device('/GPU:0') if physical_devices else tf.device('/CPU:0'):\n",
        "        transformer_model = build_transformer_model(seq_length, d_model=64, num_heads=4, ff_dim=128)\n",
        "        es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "        transformer_model.fit(X, y, epochs=50, batch_size=32, verbose=0, callbacks=[es])\n",
        "        last_seq = scaled_data[-seq_length:]\n",
        "        preds = []\n",
        "        current_seq = last_seq.copy()\n",
        "        for _ in range(days):\n",
        "            current_seq_reshaped = current_seq.reshape(1, seq_length, 1)\n",
        "            next_pred = transformer_model.predict(current_seq_reshaped, verbose=0)[0, 0]\n",
        "            preds.append(next_pred)\n",
        "            current_seq = np.append(current_seq[1:], [[next_pred]], axis=0)\n",
        "        preds = np.array(preds).reshape(-1, 1)\n",
        "        forecast_prices = scaler.inverse_transform(preds).flatten()\n",
        "    return forecast_prices\n",
        "\n",
        "###############################################################################\n",
        "# Unified Explanation using SHAP (Single Graph)\n",
        "###############################################################################\n",
        "def unified_explanation(ticker, model_name='lstm'):\n",
        "    # Retrain a simple LSTM model on training data and produce a SHAP summary plot.\n",
        "    train, _ = split_data_with_features(ticker, train_ratio=0.8, add_features=True)\n",
        "    if train is None:\n",
        "        return\n",
        "    data = train['Close'].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    seq_length = 60\n",
        "    if len(scaled_data) < seq_length:\n",
        "        print(\"Not enough data for explanation.\")\n",
        "        return\n",
        "    X, y = create_sequences(scaled_data, seq_length)\n",
        "    if X is None:\n",
        "        return\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    with tf.device('/GPU:0') if physical_devices else tf.device('/CPU:0'):\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(50, return_sequences=False))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(1, kernel_regularizer=l2(0.001)))\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "        model.fit(X, y, epochs=50, batch_size=32, verbose=0, callbacks=[es])\n",
        "    X_sample = X[-100:].reshape(100, X.shape[1])\n",
        "    print(\"\\nGenerating unified SHAP explanation plot...\")\n",
        "    explainer = shap.Explainer(model, X_sample)\n",
        "    shap_values = explainer(X_sample)\n",
        "    shap.summary_plot(shap_values.values, X_sample, feature_names=[f\"f{i}\" for i in range(X_sample.shape[1])])\n",
        "    return shap_values\n",
        "\n",
        "###############################################################################\n",
        "# Stock Info & Analysis\n",
        "###############################################################################\n",
        "def stock_info(ticker):\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        info = stock.info\n",
        "        print(f\"\\nInformation for {ticker.upper()}:\")\n",
        "        print(\"\\n--- Basic Information ---\")\n",
        "        print(f\"  Name: {info.get('shortName', 'N/A')}\")\n",
        "        print(f\"  Sector: {info.get('sector', 'N/A')}\")\n",
        "        print(f\"  Industry: {info.get('industry', 'N/A')}\")\n",
        "        print(f\"  Country: {info.get('country', 'N/A')}\")\n",
        "        print(f\"  Website: {info.get('website', 'N/A')}\")\n",
        "        print(\"\\n--- Price Information ---\")\n",
        "        print(f\"  Current Price: ${info.get('currentPrice', info.get('previousClose', 'N/A'))}\")\n",
        "        print(f\"  Previous Close: ${info.get('previousClose', 'N/A')}\")\n",
        "        print(f\"  Open: ${info.get('open', 'N/A')}\")\n",
        "        print(f\"  Day Range: ${info.get('dayLow', 'N/A')} - ${info.get('dayHigh', 'N/A')}\")\n",
        "        print(f\"  52 Week Range: ${info.get('fiftyTwoWeekLow', 'N/A')} - ${info.get('fiftyTwoWeekHigh', 'N/A')}\")\n",
        "        print(f\"  Volume: {info.get('volume', 'N/A'):,}\")\n",
        "        print(f\"  Avg. Volume: {info.get('averageVolume', 'N/A'):,}\")\n",
        "        print(\"\\n--- Valuation Metrics ---\")\n",
        "        market_cap = info.get('marketCap', 0)\n",
        "        print(f\"  Market Cap: ${market_cap/1e9:.2f}B\")\n",
        "        print(f\"  P/E Ratio: {info.get('trailingPE', 'N/A')}\")\n",
        "        print(f\"  Forward P/E: {info.get('forwardPE', 'N/A')}\")\n",
        "        print(f\"  PEG Ratio: {info.get('pegRatio', 'N/A')}\")\n",
        "        print(f\"  Price/Sales: {info.get('priceToSalesTrailing12Months', 'N/A')}\")\n",
        "        print(f\"  Price/Book: {info.get('priceToBook', 'N/A')}\")\n",
        "        print(f\"  EV/EBITDA: {info.get('enterpriseToEbitda', 'N/A')}\")\n",
        "        print(\"\\n--- Dividend Information ---\")\n",
        "        print(f\"  Dividend Rate: ${info.get('dividendRate', 0)}\")\n",
        "        dividend_yield = info.get('dividendYield', 0)\n",
        "        print(f\"  Dividend Yield: {dividend_yield*100 if dividend_yield else 0:.2f}%\")\n",
        "        print(f\"  Ex-Dividend Date: {info.get('exDividendDate', 'N/A')}\")\n",
        "    except Exception as e:\n",
        "        print(\"Error retrieving stock info:\", e)\n",
        "\n",
        "def analyze_stock(ticker):\n",
        "    print(f\"\\n--- Analysis for {ticker.upper()} ---\")\n",
        "    stock_info(ticker)\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is not None:\n",
        "        df_features = add_technical_indicators(df)\n",
        "        print(\"\\nTechnical Indicators (first 5 rows):\")\n",
        "        print(df_features.head().to_string())\n",
        "        print(\"\\nTechnical Indicators (last 5 rows):\")\n",
        "        print(df_features.tail().to_string())\n",
        "    print(\"\\nCombined 5-Day Forecast (Averaged across models):\")\n",
        "    forecasts = ensemble_forecast(ticker, days=5)\n",
        "    if forecasts:\n",
        "        if len(forecasts) > 10:\n",
        "            print(\"Forecast (first 5 values):\", forecasts[:5])\n",
        "            print(\"Forecast (last 5 values):\", forecasts[-5:])\n",
        "        else:\n",
        "            print(\"Forecast:\", forecasts)\n",
        "        plot_multi_day_forecast(ticker, days=5, model_name='combined')\n",
        "    else:\n",
        "        print(\"No forecast available.\")\n",
        "\n",
        "def yahoo_dashboard(ticker):\n",
        "    print(f\"\\n=== Yahoo Dashboard for {ticker.upper()} ===\")\n",
        "    stock_info(ticker)\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is not None:\n",
        "        df_features = add_technical_indicators(df)\n",
        "        print(\"\\nTechnical Indicators (first 5 rows):\")\n",
        "        print(df_features.head().to_string())\n",
        "        print(\"\\nTechnical Indicators (last 5 rows):\")\n",
        "        print(df_features.tail().to_string())\n",
        "    print(\"\\nCombined 5-Day Forecast:\")\n",
        "    forecasts = ensemble_forecast(ticker, days=5)\n",
        "    if forecasts:\n",
        "        if len(forecasts) > 10:\n",
        "            print(\"Forecast (first 5 values):\", forecasts[:5])\n",
        "            print(\"Forecast (last 5 values):\", forecasts[-5:])\n",
        "        else:\n",
        "            print(\"Forecast:\", forecasts)\n",
        "        plot_multi_day_forecast(ticker, days=5, model_name='combined')\n",
        "    else:\n",
        "        print(\"No forecast available.\")\n",
        "\n",
        "###############################################################################\n",
        "# Buy/Sell Probability\n",
        "###############################################################################\n",
        "def buy_sell_probability(ticker, days=30, model='ensemble'):\n",
        "    if model == 'arima':\n",
        "        forecast = forecast_arima(ticker, days=days)\n",
        "    elif model == 'lstm':\n",
        "        forecast = forecast_lstm(ticker, days=days)\n",
        "    elif model == 'gru':\n",
        "        forecast = forecast_gru(ticker, days=days)\n",
        "    elif model == 'rf':\n",
        "        forecast = forecast_rf(ticker, days=days)\n",
        "    elif model == 'gb':\n",
        "        forecast = forecast_gb(ticker, days=days)\n",
        "    elif model in ['ensemble','combined']:\n",
        "        forecast = ensemble_forecast(ticker, days=days)\n",
        "    else:\n",
        "        print(\"Model not recognized for probability analysis.\")\n",
        "        return None\n",
        "    if forecast is None:\n",
        "        return None\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is None:\n",
        "        return None\n",
        "    current_price = float(df['Close'].iloc[-1])\n",
        "    prob_up = np.mean(np.array(forecast) > current_price)\n",
        "    prob_down = 1 - prob_up\n",
        "    expected_return = np.mean(np.array(forecast)/current_price - 1) * 100\n",
        "    print(f\"\\nBuy/Sell Probability for {ticker.upper()} ({days}-day horizon):\")\n",
        "    print(f\"  Current Price: ${current_price:.2f}\")\n",
        "    print(f\"  Probability of Price Increase: {prob_up*100:.1f}%\")\n",
        "    print(f\"  Probability of Price Decrease: {prob_down*100:.1f}%\")\n",
        "    print(f\"  Expected Return: {expected_return:.2f}%\")\n",
        "    return {\n",
        "        'current_price': current_price,\n",
        "        'prob_up': prob_up,\n",
        "        'prob_down': prob_down,\n",
        "        'expected_return': expected_return\n",
        "    }\n",
        "\n",
        "###############################################################################\n",
        "# Portfolio Management\n",
        "###############################################################################\n",
        "def portfolio_add(ticker, shares):\n",
        "    ticker = ticker.upper()\n",
        "    portfolio[ticker] = portfolio.get(ticker, 0) + shares\n",
        "    print(f\"Added {shares} shares of {ticker} to portfolio.\")\n",
        "\n",
        "def portfolio_show():\n",
        "    if not portfolio:\n",
        "        print(\"Portfolio is empty.\")\n",
        "    else:\n",
        "        print(\"Current Portfolio:\")\n",
        "        for tk, sh in portfolio.items():\n",
        "            print(f\"{tk}: {sh} shares\")\n",
        "\n",
        "def portfolio_clear():\n",
        "    portfolio.clear()\n",
        "    print(\"Portfolio cleared.\")\n",
        "\n",
        "###############################################################################\n",
        "# Helper to Retrieve Forecast\n",
        "###############################################################################\n",
        "def get_forecast(ticker, days, model):\n",
        "    if model == 'arima':\n",
        "        return forecast_arima(ticker, days=days)\n",
        "    elif model == 'lstm':\n",
        "        return forecast_lstm(ticker, days=days)\n",
        "    elif model == 'gru':\n",
        "        return forecast_gru(ticker, days=days)\n",
        "    elif model == 'rf':\n",
        "        return forecast_rf(ticker, days=days)\n",
        "    elif model == 'gb':\n",
        "        return forecast_gb(ticker, days=days)\n",
        "    elif model in ['ensemble', 'combined']:\n",
        "        return ensemble_forecast(ticker, days=days)\n",
        "    elif model == 'advanced':\n",
        "        return forecast_tft(ticker, days=days)\n",
        "    else:\n",
        "        print(f\"Model '{model}' not recognized.\")\n",
        "        return None\n",
        "\n",
        "###############################################################################\n",
        "# Evaluate Model Function\n",
        "###############################################################################\n",
        "def evaluate_model(ticker, model_name='lstm', plot=True):\n",
        "    train, test = split_data_with_features(ticker, train_ratio=0.8, add_features=True)\n",
        "    if train is None or test is None:\n",
        "        return\n",
        "    horizon = min(len(test), 30)\n",
        "    if model_name == 'arima':\n",
        "        forecast = forecast_arima(ticker, days=horizon, df_input=train)\n",
        "    elif model_name == 'lstm':\n",
        "        forecast = forecast_lstm(ticker, days=horizon, df_input=train)\n",
        "    elif model_name == 'gru':\n",
        "        forecast = forecast_gru(ticker, days=horizon, df_input=train)\n",
        "    elif model_name == 'rf':\n",
        "        forecast = forecast_rf(ticker, days=horizon, df_input=train)\n",
        "    elif model_name == 'gb':\n",
        "        forecast = forecast_gb(ticker, days=horizon, df_input=train)\n",
        "    elif model_name in ['ensemble', 'combined']:\n",
        "        forecast = ensemble_forecast(ticker, days=horizon, df_input=train)\n",
        "    elif model_name == 'advanced':\n",
        "        forecast = forecast_tft(ticker, days=horizon)\n",
        "    else:\n",
        "        print(f\"Model '{model_name}' not recognized for evaluation.\")\n",
        "        return\n",
        "    if forecast is None:\n",
        "        print(\"Forecast generation failed or interrupted.\")\n",
        "        return\n",
        "    test_values = test['Close'].iloc[:horizon].values.astype(float)\n",
        "    forecast = np.array(forecast[:horizon])\n",
        "    rmse = np.sqrt(mean_squared_error(test_values, forecast))\n",
        "    mae = mean_absolute_error(test_values, forecast)\n",
        "    mape = np.mean(np.abs((test_values - forecast)/test_values)) * 100\n",
        "    r2 = r2_score(test_values, forecast)\n",
        "    print(f\"\\nEvaluation for {ticker.upper()} using {model_name.upper()}:\")\n",
        "    print(f\"  Forecast Horizon: {horizon} days\")\n",
        "    print(f\"  RMSE: {rmse:.2f}\")\n",
        "    print(f\"  MAE: {mae:.2f}\")\n",
        "    print(f\"  MAPE: {mape:.2f}%\")\n",
        "    print(f\"  R² Score: {r2:.4f}\")\n",
        "    if len(forecast) > 10:\n",
        "        print(\"\\nForecast (first 5 values):\", forecast[:5])\n",
        "        print(\"Forecast (last 5 values):\", forecast[-5:])\n",
        "    else:\n",
        "        print(\"\\nForecast:\", forecast)\n",
        "    if plot:\n",
        "        last_train_date = train.index[-1]\n",
        "        forecast_dates = pd.date_range(start=test.index[0], periods=horizon, freq='B')\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.plot(train.index[-30:], train['Close'].iloc[-30:], label='Training Data', color='blue', alpha=0.5)\n",
        "        plt.plot(test.index[:horizon], test_values, label='Actual', color='black', linewidth=2)\n",
        "        plt.plot(forecast_dates, forecast, label=f'{model_name.upper()} Forecast', color='red', marker='x')\n",
        "        plt.axvline(x=last_train_date, color='gray', linestyle='--', label='Forecast Start')\n",
        "        plt.title(f'{ticker.upper()} - {model_name.upper()} Model Evaluation')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Price ($)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{plot_dir}/{ticker}_{model_name}_evaluation.png\")\n",
        "        plt.show()\n",
        "    return rmse, mae, mape, r2\n",
        "\n",
        "###############################################################################\n",
        "# Multi-Day Forecast Visualization (Matplotlib)\n",
        "###############################################################################\n",
        "def plot_multi_day_forecast(ticker, days, model_name='lstm'):\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is None:\n",
        "        return\n",
        "    if model_name == 'arima':\n",
        "        forecast = forecast_arima(ticker, days=days)\n",
        "    elif model_name == 'lstm':\n",
        "        forecast = forecast_lstm(ticker, days=days)\n",
        "    elif model_name == 'gru':\n",
        "        forecast = forecast_gru(ticker, days=days)\n",
        "    elif model_name == 'rf':\n",
        "        forecast = forecast_rf(ticker, days=days)\n",
        "    elif model_name == 'gb':\n",
        "        forecast = forecast_gb(ticker, days=days)\n",
        "    elif model_name in ['ensemble', 'combined']:\n",
        "        forecast = ensemble_forecast(ticker, days=days)\n",
        "    elif model_name == 'advanced':\n",
        "        forecast = forecast_tft(ticker, days=days)\n",
        "    else:\n",
        "        print(f\"Model '{model_name}' not recognized.\")\n",
        "        return\n",
        "    if forecast is None:\n",
        "        return\n",
        "    hist = df.tail(30)\n",
        "    last_date = df.index[-1]\n",
        "    forecast_dates = pd.date_range(last_date, periods=days+1, freq='B')[1:]\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.plot(hist.index, pd.to_numeric(hist['Close'], errors='coerce'), marker='o', label='Historical')\n",
        "    plt.plot([last_date, forecast_dates[0]], [hist['Close'].iloc[-1], forecast[0]], linestyle='-', color='green')\n",
        "    plt.plot(forecast_dates, forecast, marker='o', linestyle='-', color='red', label=f'{model_name.upper()} Forecast')\n",
        "    plt.title(f\"{ticker.upper()} - {days}-Day Forecast ({model_name.upper()})\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price ($)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{plot_dir}/{ticker}_{model_name}_forecast.png\")\n",
        "    plt.show()\n",
        "    print(f\"\\nForecast for the next {days} days for {ticker.upper()} using {model_name.upper()}:\")\n",
        "    for i, (d, p) in enumerate(zip(forecast_dates, forecast), start=1):\n",
        "        print(f\"  {d.strftime('%Y-%m-%d')} (Day {i}): ${p:.2f}\")\n",
        "\n",
        "###############################################################################\n",
        "# Interactive Candlestick Chart (Plotly)\n",
        "###############################################################################\n",
        "def interactive_candlestick_chart(ticker, period=\"1mo\", interval=\"1d\"):\n",
        "    df = yf.download(ticker, period=period, interval=interval, progress=False)\n",
        "    if df.empty:\n",
        "        print(f\"No data found for {ticker.upper()} with period={period} and interval={interval}.\")\n",
        "        return\n",
        "    candlestick = go.Candlestick(\n",
        "        x=df.index,\n",
        "        open=df['Open'],\n",
        "        high=df['High'],\n",
        "        low=df['Low'],\n",
        "        close=df['Close'],\n",
        "        name='OHLC'\n",
        "    )\n",
        "    volume_bar = go.Bar(\n",
        "        x=df.index,\n",
        "        y=df['Volume'],\n",
        "        name='Volume',\n",
        "        marker_color='rgba(100, 150, 250, 0.5)',\n",
        "        yaxis='y2'\n",
        "    )\n",
        "    fig = go.Figure(data=[candlestick, volume_bar])\n",
        "    fig.update_layout(\n",
        "        title=f\"{ticker.upper()} Candlestick Chart ({period}, {interval})\",\n",
        "        xaxis_title=\"Date\",\n",
        "        yaxis_title=\"Price\",\n",
        "        hovermode=\"x unified\",\n",
        "        template=\"plotly_dark\",\n",
        "        yaxis=dict(domain=[0.2, 1]),\n",
        "        yaxis2=dict(\n",
        "            domain=[0, 0.2],\n",
        "            overlaying='y',\n",
        "            anchor='x',\n",
        "            side='right'\n",
        "        )\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "###############################################################################\n",
        "# Interactive Forecast Visualization (Plotly)\n",
        "###############################################################################\n",
        "def interactive_plot_forecast(ticker, days, model_name='lstm'):\n",
        "    df = download_and_preprocess(ticker)\n",
        "    if df is None:\n",
        "        return\n",
        "    if model_name == 'arima':\n",
        "        forecast = forecast_arima(ticker, days=days)\n",
        "    elif model_name == 'lstm':\n",
        "        forecast = forecast_lstm(ticker, days=days)\n",
        "    elif model_name == 'gru':\n",
        "        forecast = forecast_gru(ticker, days=days)\n",
        "    elif model_name == 'rf':\n",
        "        forecast = forecast_rf(ticker, days=days)\n",
        "    elif model_name == 'gb':\n",
        "        forecast = forecast_gb(ticker, days=days)\n",
        "    elif model_name in ['ensemble', 'combined']:\n",
        "        forecast = ensemble_forecast(ticker, days=days)\n",
        "    elif model_name == 'advanced':\n",
        "        forecast = forecast_tft(ticker, days=days)\n",
        "    else:\n",
        "        print(f\"Model '{model_name}' not recognized.\")\n",
        "        return\n",
        "    if forecast is None:\n",
        "        print(\"Forecast not available.\")\n",
        "        return\n",
        "    hist = df.tail(60)\n",
        "    last_date = df.index[-1]\n",
        "    forecast_dates = pd.date_range(last_date, periods=days+1, freq='B')[1:]\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=hist.index, y=hist['Close'],\n",
        "                             mode='lines+markers',\n",
        "                             name='Historical'))\n",
        "    fig.add_trace(go.Scatter(x=forecast_dates, y=forecast,\n",
        "                             mode='lines+markers',\n",
        "                             name=f'{model_name.upper()} Forecast'))\n",
        "    fig.update_layout(title=f\"{ticker.upper()} - {days}-Day Forecast ({model_name.upper()})\",\n",
        "                      xaxis_title=\"Date\",\n",
        "                      yaxis_title=\"Price ($)\",\n",
        "                      template=\"plotly_dark\",\n",
        "                      hovermode=\"x unified\")\n",
        "    fig.show()\n",
        "\n",
        "###############################################################################\n",
        "# FINAL Summary Command (Unified Explanation Graph)\n",
        "###############################################################################\n",
        "def final_summary(ticker, days=5, model='lstm'):\n",
        "    \"\"\"\n",
        "    Shows everything about projections in one shot:\n",
        "      1) Evaluates the chosen model (RMSE, MAE, MAPE, R², etc.)\n",
        "      2) Prints forecast values\n",
        "      3) Displays an interactive candlestick chart for the last 3 months\n",
        "      4) Displays a unified SHAP explanation graph\n",
        "      5) Displays an interactive forecast chart\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== FINAL SUMMARY for {ticker.upper()}, {days}-day, Model: {model.upper()} ===\\n\")\n",
        "\n",
        "    # 1) Evaluate model (without plotting)\n",
        "    metrics = evaluate_model(ticker, model_name=model, plot=False)\n",
        "    if metrics is None:\n",
        "        print(\"Evaluation failed.\")\n",
        "    # 2) Print forecast values\n",
        "    forecast = get_forecast(ticker, days, model)\n",
        "    if forecast is not None:\n",
        "        print(\"\\nForecast values:\")\n",
        "        for i, val in enumerate(forecast, start=1):\n",
        "            print(f\"  Day {i}: ${val:.2f}\")\n",
        "    else:\n",
        "        print(\"No forecast available.\")\n",
        "\n",
        "    # 3) Interactive candlestick chart (3mo, 1d)\n",
        "    print(\"\\nLaunching interactive candlestick chart (3mo, 1d)...\")\n",
        "    interactive_candlestick_chart(ticker, period=\"3mo\", interval=\"1d\")\n",
        "\n",
        "    # 4) Unified SHAP explanation graph\n",
        "    print(\"\\nGenerating unified SHAP explanation using SHAP...\")\n",
        "    unified_explanation(ticker, model_name=model)\n",
        "\n",
        "    # 5) Interactive forecast chart\n",
        "    print(\"\\nLaunching interactive forecast chart...\")\n",
        "    interactive_plot_forecast(ticker, days, model_name=model)\n",
        "\n",
        "    print(\"\\n=== END OF FINAL SUMMARY ===\")\n",
        "\n",
        "###############################################################################\n",
        "# Command Parsing & Main Loop\n",
        "###############################################################################\n",
        "def print_help():\n",
        "    help_text = \"\"\"\n",
        "Available Commands:\n",
        "\n",
        "Basic Analysis:\n",
        "  raw TICKER                  -> Display first 5 and last 5 rows of raw data for TICKER\n",
        "  preprocessed TICKER         -> Display cleaned data (first 5 & last 5 rows) for TICKER\n",
        "  features TICKER             -> Display technical indicators (first 5 & last 5 rows) for TICKER\n",
        "  evaluation TICKER           -> Evaluate model and show error metrics with forecast\n",
        "  advanced TICKER             -> Forecast using an advanced (Transformer-based) model\n",
        "  sentiment HEADLINE          -> Analyze sentiment of a news headline\n",
        "\n",
        "Data Splitting:\n",
        "  split TICKER                -> Split data into training and testing sets\n",
        "\n",
        "Forecasting & Comparison:\n",
        "  oneday TICKER               -> 1-day forecast using combined (ensemble) models\n",
        "  arima TICKER                -> 1-day forecast using ARIMA\n",
        "  lstm TICKER                 -> 1-day forecast using LSTM\n",
        "  gru TICKER                  -> 1-day forecast using GRU\n",
        "  rf TICKER                   -> 1-day forecast using RandomForest\n",
        "  gb TICKER                   -> 1-day forecast using XGBoost\n",
        "  combined TICKER             -> 1-day forecast using ensemble models (average)\n",
        "  predict TICKER DAYS [MODEL] -> Forecast for custom horizon (default: lstm)\n",
        "  interactive TICKER DAYS [MODEL] -> Interactive forecast visualization (Plotly)\n",
        "  candlestick TICKER [PERIOD] [INTERVAL] -> Interactive candlestick chart\n",
        "\n",
        "Stock Info & Analysis:\n",
        "  info TICKER                 -> Display stock information\n",
        "  analyze TICKER              -> Comprehensive analysis (info, technicals, 5-day forecast)\n",
        "  yahoo TICKER                -> Yahoo Finance-like dashboard\n",
        "\n",
        "Probability:\n",
        "  probability TICKER          -> Buy/Sell probability (30-day horizon, default: ensemble)\n",
        "\n",
        "Visualization:\n",
        "  chart TICKER                -> Display raw ticker chart\n",
        "  context TICKER [MODEL]      -> Last 6 days historical + next 6 days forecast (default: ensemble)\n",
        "  zoom TICKER [MODEL]         -> 15-day zoom forecast chart (default: combined)\n",
        "\n",
        "Backtesting:\n",
        "  walkforward TICKER          -> Perform walk-forward validation\n",
        "\n",
        "Portfolio Management:\n",
        "  portfolio add TICKER SHARES -> Add shares of TICKER to portfolio\n",
        "  portfolio show              -> Display current portfolio\n",
        "  portfolio clear             -> Clear portfolio\n",
        "\n",
        "FINAL Command:\n",
        "  final TICKER DAYS [MODEL]   -> Shows everything about projections in one shot (with unified explanation)\n",
        "\n",
        "Misc:\n",
        "  rawticker TICKER            -> Display first 5 and last 5 rows of raw data for TICKER\n",
        "  help                        -> Show this help message\n",
        "  exit                        -> Quit the CLI\n",
        "\"\"\"\n",
        "    print(help_text)\n",
        "\n",
        "def process_command(command):\n",
        "    stop_event.clear()\n",
        "    tokens = command.split()\n",
        "    if not tokens:\n",
        "        return\n",
        "    cmd = tokens[0].lower()\n",
        "    if cmd in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        return \"exit\"\n",
        "    if cmd == 'help':\n",
        "        print_help()\n",
        "        return\n",
        "    if cmd == 'rawticker' and len(tokens) == 2:\n",
        "        raw_ticker_values(tokens[1])\n",
        "        return\n",
        "    if cmd == 'raw' and len(tokens) == 2:\n",
        "        raw_ticker_values(tokens[1])\n",
        "        return\n",
        "    if cmd == 'preprocessed' and len(tokens) == 2:\n",
        "        df = download_and_preprocess(tokens[1])\n",
        "        if df is not None:\n",
        "            print(\"First 5 rows:\")\n",
        "            print(df.head().to_string())\n",
        "            print(\"\\nLast 5 rows:\")\n",
        "            print(df.tail().to_string())\n",
        "        return\n",
        "    if cmd == 'features' and len(tokens) == 2:\n",
        "        df = download_and_preprocess(tokens[1])\n",
        "        if df is not None:\n",
        "            df_features = add_technical_indicators(df)\n",
        "            print(\"First 5 rows:\")\n",
        "            print(df_features.head().to_string())\n",
        "            print(\"\\nLast 5 rows:\")\n",
        "            print(df_features.tail().to_string())\n",
        "        return\n",
        "    if cmd == 'evaluation' and len(tokens) == 2:\n",
        "        evaluate_model(tokens[1])\n",
        "        return\n",
        "    if cmd == 'advanced' and len(tokens) == 2:\n",
        "        evaluate_model(tokens[1], model_name='advanced')\n",
        "        return\n",
        "    if cmd == 'sentiment' and len(tokens) >= 2:\n",
        "        headline = \" \".join(tokens[1:])\n",
        "        result = analyze_sentiment(headline)\n",
        "        print(f\"Sentiment analysis for the headline:\\n{headline}\\nResult: {result}\")\n",
        "        return\n",
        "    if cmd == 'split' and len(tokens) == 2:\n",
        "        split_data_with_features(tokens[1])\n",
        "        return\n",
        "    if cmd == 'walkforward' and len(tokens) == 2:\n",
        "        # Ensure walk_forward_validation is defined; here we use the same as split-based\n",
        "        try:\n",
        "            from pandas.tseries.offsets import BDay\n",
        "        except ImportError:\n",
        "            pass\n",
        "        # For simplicity, we'll call evaluate_model for walk-forward simulation.\n",
        "        print(\"Walk-forward validation is not fully implemented in this version.\")\n",
        "        return\n",
        "    if cmd == 'oneday' and len(tokens) == 2:\n",
        "        plot_multi_day_forecast(tokens[1], days=1, model_name='combined')\n",
        "        return\n",
        "    if cmd in ['arima', 'lstm', 'gru', 'rf', 'gb', 'combined'] and len(tokens) == 2:\n",
        "        model_used = tokens[0].lower()\n",
        "        plot_multi_day_forecast(tokens[1], days=1, model_name=model_used)\n",
        "        return\n",
        "    if cmd == 'predict' and len(tokens) >= 3:\n",
        "        ticker = tokens[1]\n",
        "        try:\n",
        "            days = int(tokens[2])\n",
        "        except ValueError:\n",
        "            print(\"Days must be an integer.\")\n",
        "            return\n",
        "        model = tokens[3].strip(\"[]\").lower() if len(tokens) >= 4 else 'lstm'\n",
        "        plot_multi_day_forecast(ticker, days, model_name=model)\n",
        "        return\n",
        "    if cmd == 'interactive' and len(tokens) >= 3:\n",
        "        ticker = tokens[1]\n",
        "        try:\n",
        "            days = int(tokens[2])\n",
        "        except ValueError:\n",
        "            print(\"Days must be an integer.\")\n",
        "            return\n",
        "        model = tokens[3].strip(\"[]\").lower() if len(tokens) >= 4 else 'lstm'\n",
        "        interactive_plot_forecast(ticker, days, model_name=model)\n",
        "        return\n",
        "    if cmd == 'candlestick' and len(tokens) >= 2:\n",
        "        ticker = tokens[1]\n",
        "        period = tokens[2] if len(tokens) >= 3 else \"1mo\"\n",
        "        interval = tokens[3] if len(tokens) >= 4 else \"1d\"\n",
        "        interactive_candlestick_chart(ticker, period=period, interval=interval)\n",
        "        return\n",
        "    if cmd == 'info' and len(tokens) == 2:\n",
        "        stock_info(tokens[1])\n",
        "        return\n",
        "    if cmd == 'analyze' and len(tokens) == 2:\n",
        "        analyze_stock(tokens[1])\n",
        "        return\n",
        "    if cmd == 'yahoo' and len(tokens) == 2:\n",
        "        yahoo_dashboard(tokens[1])\n",
        "        return\n",
        "    if cmd == 'probability' and len(tokens) == 2:\n",
        "        buy_sell_probability(tokens[1], days=30, model='ensemble')\n",
        "        return\n",
        "    if cmd == 'context' and len(tokens) >= 2:\n",
        "        ticker = tokens[1]\n",
        "        model = tokens[2].lower() if len(tokens) == 3 else 'ensemble'\n",
        "        try:\n",
        "            from pandas.tseries.offsets import BDay\n",
        "        except ImportError:\n",
        "            pass\n",
        "        df = download_and_preprocess(ticker)\n",
        "        if df is None:\n",
        "            return\n",
        "        hist = df.tail(6)\n",
        "        if model == 'arima':\n",
        "            forecast = forecast_arima(ticker, days=6)\n",
        "        elif model == 'lstm':\n",
        "            forecast = forecast_lstm(ticker, days=6)\n",
        "        elif model == 'gru':\n",
        "            forecast = forecast_gru(ticker, days=6)\n",
        "        elif model == 'rf':\n",
        "            forecast = forecast_rf(ticker, days=6)\n",
        "        elif model == 'gb':\n",
        "            forecast = forecast_gb(ticker, days=6)\n",
        "        elif model in ['ensemble', 'combined']:\n",
        "            forecast = ensemble_forecast(ticker, days=6)\n",
        "        else:\n",
        "            print(\"Model not recognized.\")\n",
        "            return\n",
        "        if forecast is None:\n",
        "            return\n",
        "        last_date = df.index[-1]\n",
        "        forecast_dates = pd.date_range(last_date, periods=7, freq=BDay())[1:]\n",
        "        plt.figure(figsize=(10,6))\n",
        "        plt.plot(hist.index, hist['Close'].astype(float), marker='o', label='Historical (Last 6 Days)', color='blue')\n",
        "        plt.plot(forecast_dates, forecast, marker='o', linestyle='--', color='red', label=f'Forecast ({model.upper()})')\n",
        "        plt.axvline(x=last_date, color='gray', linestyle='--', label='Forecast Start')\n",
        "        plt.title(f\"{ticker.upper()} - Context (Last 6 Days + Next 6 Days Forecast)\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Price\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "        return\n",
        "    if cmd == 'zoom' and len(tokens) >= 2:\n",
        "        ticker = tokens[1]\n",
        "        model = tokens[2].lower() if len(tokens) == 3 else 'combined'\n",
        "        plot_multi_day_forecast(ticker, days=15, model_name=model)\n",
        "        return\n",
        "    if cmd == 'chart' and len(tokens) == 2:\n",
        "        df = download_and_preprocess(tokens[1])\n",
        "        if df is not None:\n",
        "            plt.figure(figsize=(12,6))\n",
        "            plt.plot(df.index, df['Close'], label='Close Price')\n",
        "            plt.title(f\"{tokens[1].upper()} - Raw Ticker Chart\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Price ($)\")\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "        return\n",
        "    if cmd == 'portfolio' and len(tokens) > 1:\n",
        "        sub_cmd = tokens[1].lower()\n",
        "        if sub_cmd == 'add' and len(tokens) == 4:\n",
        "            try:\n",
        "                shares = int(tokens[3])\n",
        "                portfolio_add(tokens[2], shares)\n",
        "            except ValueError:\n",
        "                print(\"Invalid number of shares.\")\n",
        "        elif sub_cmd == 'show':\n",
        "            portfolio_show()\n",
        "        elif sub_cmd == 'clear':\n",
        "            portfolio_clear()\n",
        "        else:\n",
        "            print(\"Invalid portfolio command.\")\n",
        "        return\n",
        "    if cmd == 'final' and len(tokens) >= 2:\n",
        "        ticker = tokens[1]\n",
        "        try:\n",
        "            days = int(tokens[2])\n",
        "        except ValueError:\n",
        "            days = 5\n",
        "        model = tokens[3].lower() if len(tokens) >= 4 else 'lstm'\n",
        "        final_summary(ticker, days=days, model=model)\n",
        "        return\n",
        "    print(\"Command not recognized. Type 'help' for a list of commands.\")\n",
        "\n",
        "###############################################################################\n",
        "# Main Loop (Keeps running until 'exit' or 'quit' is typed)\n",
        "###############################################################################\n",
        "current_thread = None\n",
        "\n",
        "def command_loop():\n",
        "    global current_thread\n",
        "    print(\"Welcome to the Stock Analysis CLI!\")\n",
        "    print(\"Type 'help' for a list of commands or 'exit' to quit.\")\n",
        "    while True:\n",
        "        cmd = input(\">> \").strip()\n",
        "        if current_thread and current_thread.is_alive():\n",
        "            stop_event.set()  # Cancel any running task\n",
        "        stop_event.clear()\n",
        "        current_thread = threading.Thread(target=process_command, args=(cmd,))\n",
        "        current_thread.start()\n",
        "        if cmd.lower() in ['exit', 'quit']:\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    command_loop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evauation\n",
        "### RMSE (Root Mean Squared Error)\n",
        "**Ideal**: The lower, the better.\n",
        "**Interpretation**: Measures the average squared difference between predicted and actual values.\n",
        "**Stock Market Rule of Thumb**:\n",
        "Should be much lower than the stock's price range.\n",
        "If the stock trades at ₹3000, an RMSE of ₹30–₹50 is acceptable.\n",
        "If RMSE is too high, the model has poor accuracy.\n",
        "## MAE (Mean Absolute Error)\n",
        "**Ideal**: Lower is better, but should be close to RMSE.\n",
        "**Interpretation**: Measures the average absolute error between predictions and actual values.\n",
        "## MAPE (Mean Absolute Percentage Error)\n",
        "**Ideal**: Less than 5% for stock market predictions.\n",
        "**Interpretation**: Shows the percentage deviation from actual prices.\n",
        "**Stock Market Rule of Thumb**:\n",
        "Below 5% → Good model\n",
        "5% to 10% → Acceptable\n",
        "Above 10% → Poor model (needs improvement)\n",
        "## R² Score (Coefficient of Determination)\n",
        "**Ideal**: Close to 1 (higher is better).\n",
        "**Interpretation**: Measures how well the model explains variance in stock prices.\n",
        "**Stock Market Rule of Thumb**:\n",
        "Above 0.80 → Strong model\n",
        "0.50 to 0.80 → Moderate accuracy\n",
        "Below 0.50 → Weak model\n",
        "Negative R² → Worse than random guessing (needs major improvement!)"
      ],
      "metadata": {
        "id": "VsWrdHGGzF1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "KkSDNbBVzEc7"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMm39e0LDBjaC5fgRwkBGZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}